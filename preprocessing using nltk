#pre processing the sentence and removing stop words

""" Input paragraph for our pre-processing """
my_para = "I bought a Phone today...          The phone is very nice :)      "
 
""" Removing extra white spaces using regular expressions """
import re
my_para = re.sub('\s+', ' ', my_para)
print my_para
# I bought a Phone today... The phone is very nice :) #

 
""" Removing the extra periods using regular expressions """
my_para = re.sub('\.+', '.', my_para)
print my_para
# I bought a Phone today. The phone is very nice :) #

 
""" Removing the special characters using string replace """
special_char_list = [':', ';', '?', '}', ')', '{', '(']
for special_char in special_char_list:
    my_para = my_para.replace(special_char, '')
print my_para
# I bought a Phone today. The phone is very nice #

 
""" Standardizing the text by converting them to lower case """
my_para = my_para.strip().lower()
print my_para
# i bought a phone today. the phone is very nice #

 
""" Imporing the necessary modules for stopwords removal"""
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
eng_stopwords = stopwords.words('english')     ## eng_stopwords is the list of english stopwords
# stop words are the most commonly used english words like a, the, and 

""" Tokenizing the paragraph first and then removing the stop words """
#tokenization means breaking up the text into tokens(words, numbers or punctuation)
wordList = word_tokenize(my_para)                                     ## Tokenizing the paragraph
wordList = [word for word in wordList if word not in eng_stopwords]   ## Removing the stopwords
print wordList
# ['bought', 'phone', 'today', '.', 'phone', 'nice'] # 









#splitting the para into sentence and then words

""" Input paragraph """
my_para = "This is first sentence. And this is second."

""" splitting the paragraph into sentences using split funtion """
sentences_list = my_para.strip().split(".")

""" Getting the first sentence from the output and printing it """
first_sentence = sentences_list[0]
print first_sentence
# This is first sentence #

""" Splitting the first sentence into words using split function again """
words_list = first_sentence.strip().split(" ")
print words_list
# ['This', 'is', 'first', 'sentence'] # 
